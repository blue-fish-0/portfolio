{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"knime_etl/","title":"Extract, Transform, Load (ETL) using KNIME and SQL Server","text":""},{"location":"knime_etl/#summary","title":"Summary","text":"<p> Problem: The analytics team spent a lot of time cleaning the sales and inventory data that they received in Excel files every day. </p> <p> Solution: I used KNIME to develop an ETL program to extract the data from the Excel files, transform the data, then load the transformed data into SQL Server.</p> <p> Results: The analytics team can simply query data from SQL Server instead of wrangling data from thousands of Excel files. </p>"},{"location":"knime_etl/#knime","title":"KNIME","text":"<p>KNIME is a low-code data processing app where you can chain \u201cnodes\u201d to create programs. A node is like a function in a programming language. </p> <p></p> <p>Screenshot of KNIME.</p>"},{"location":"knime_etl/#definitions","title":"Definitions","text":"<code>f</code> An Excel file containing sales and inventory data for one day.  <code>f.data</code> The data table extracted from <code>f</code>. All columns in <code>f.data</code> are the string data type.  <code>T</code> <p>A sequence of data transformations. These include:  </p> <ul> <li>Transforming column contents using regular expressions.  </li> <li>Converting column data types.  </li> </ul> <code>T(f.data)</code> The resulting table after applying <code>T</code> to <code>f.data</code>.  <code>all_data</code> A database table that stores <code>T(f.data)</code> for every Excel file <code>f</code>. match A table <code>A</code> matches a table <code>B</code> if <code>A</code> and <code>B</code> have the same column names and data types. <code>T(f.data)</code> can only be loaded into <code>all_data</code> if <code>T(f.data)</code> matches <code>all_data</code>. <code>L_all</code> A list of all the Excel file names. <code>L_loaded</code> A list of the Excel file names <code>f.name</code> such that <code>T(f.data)</code> has been loaded into <code>all_data</code>."},{"location":"knime_etl/#pseudocode-of-the-etl-program","title":"Pseudocode of the ETL program","text":"<pre>\nAlgorithm ETL_program(L):  \n    Input:   \n        L: A list of Excel file names.\n    Output: Nothing. \n\n    for each Excel file name f.name in L:\n        f.data = Extract the data table from f.  \n        T(f.data) = Apply each transformation in T to f.data. \n        try:\n            Compare the column names and data types in T(f.data) and \n            all_data. If T(f.data) doesn\u2019t match all_data, raise an \n            exception describing the mismatching columns.\n        except Exception as error:\n            Print f\"{f}: {error}\" (a formatted string).   \n        else:\n            if f.name is not in L_loaded: \n                Load T(f.data) into all_data.\n                Append f.name to L_loaded.   \n</pre> <p> <code>(L_all \u2212 L_loaded)</code> is the list of the Excel file names <code>f.name</code> such that <code>T(f.data)</code> hasn't been  loaded into <code>all_data</code>. </p> <p>After executing <code>ETL_program(L_all - L_loaded)</code>, I execute the following steps manually:</p> <pre>\nwhile (L_all - L_loaded) is not empty:\n    f.name = (L_all - L_loaded)[0].\n        Execute ETL_program([f.name]). \n        Use the printed error message to update the data \n        transformations in T.\n    Execute ETL_program(L_all - L_loaded). \n</pre>"},{"location":"knime_etl/#example-execution-of-the-etl-program","title":"Example execution of the ETL program","text":"<code>T</code>: <ol> <li>Convert <code>date</code> to the date data type.    </li> <li>Convert <code>column_a</code> to the integer data type.   </li> </ol> <p>1. Execute <code>ETL_program([f_1.name])</code>: </p> <p></p> <p><code>T(f_1.data)</code> can't be loaded into <code>all_data</code> because <code>\"missing\"</code> in <code>column_a</code> can't be converted to an integer. </p> <p>2. Update <code>T</code>: </p> <code>T</code>: <ol> <li>Convert <code>date</code> to the date data type.    </li> <li>In <code>column_a</code>, replace all cells matching the regular expression <code>\u201c^missing$\u201d</code> with <code>null</code>.</li> <li>Convert <code>column_a</code> to the integer data type.</li> </ol> <p>3. Execute <code>ETL_program([f_1.name])</code>: </p> <p></p> <p>After updating <code>T</code>, <code>T(f_1.data)</code> is loaded into <code>all_data</code>.</p>"},{"location":"power_bi_python/","title":"Creating Power BI report pages using Python","text":""},{"location":"power_bi_python/#summary","title":"Summary","text":"<p> Problem: The analytics team needed to create hundreds of Power BI report pages, each presenting the data of a different database query. </p> <p> Solution: I wrote a Python script to automate the creation of the Power BI report pages by editing the files in a Power BI Project folder. </p> <p> Results: The Python script saved days of work for my team. Without the script, we would have had to manually create the report pages using the Power BI graphical user interface (GUI). </p>"},{"location":"power_bi_python/#power-bi-projects-pbip","title":"Power BI Projects (PBIP)","text":"<p>A Power BI Project (PBIP) defines a Power BI report using a folder of plain text files. By using PBIPs, we can edit Power BI reports using a programming language, such as Python.     </p> project/<pre><code> \ud83d\udcc2.SemanticModel\n \ud83d\udcdc.pbip\n \ud83d\udcc2.Report\n</code></pre>"},{"location":"power_bi_python/#semanticmodel-folder","title":"<code>.SemanticModel</code> folder","text":"<p>Defines the data tables that are used to create the data visualizations in the report pages. </p> project/.SemanticModel/<pre><code> \ud83d\udcc2tables # (1)!\n \u2523 \ud83d\udcdctable_1.tmdl\n \u2517 \ud83d\udcdctemplate_table.tmdl\n</code></pre> <ol> <li>Each <code>.tmdl</code> file in the <code>tables</code> folder defines a semantic model table. For example, the file contains the Power Query M code that produces the table. </li> </ol>"},{"location":"power_bi_python/#pbip-file","title":"<code>.pbip</code> file","text":"<p>A Power BI report such that changes made to the <code>.Report</code> and <code>.SemanticModel</code> folders will change the <code>.pbip</code> file. Furthermore, changes made to the <code>.pbip</code> file using the Power BI GUI will change the <code>.Report</code> and <code>.SemanticModel</code> folders. </p> <p>I used the Power BI GUI to create a <code>template_table</code> report page, which presents the data from the <code>template_table</code> semantic model table. The <code>template_table</code> report page defines the appearance of the report pages that the Python script will create.  </p> <p></p> <p><code>project.pbip</code></p>"},{"location":"power_bi_python/#report-folder","title":"<code>.Report</code> folder","text":"<p>Defines all the report pages in the Power BI report.  </p> project/.Report/<pre><code> \ud83d\udcc2definition\n \u2523 \ud83d\udcc2pages # (1)!\n \u2503 \u2523 \ud83d\udcc2template_table\n \u2503 \u2503 \u2523 \ud83d\udcc2visuals\n \u2503 \u2503 \u2503 \u2517 \ud83d\udcc2line_graph\n \u2503 \u2503 \u2503 \u2503 \u2517 \ud83d\udcdcvisual.json # (2)!\n \u2503 \u2503 \u2517 \ud83d\udcdcpage.json\n</code></pre> <ol> <li>Each folder in the <code>pages</code> folder defines a report page. </li> <li>Each <code>visual.json</code> file defines a data visualization. For example, the file specifies the type of data visualization, and which semantic model tables to use to create the visualization. </li> </ol>"},{"location":"power_bi_python/#python-code","title":"Python code","text":"<p>I used the following Python packages: </p> <ul> <li> <code>pathlib</code> to represent filesystem paths. </li> <li> <code>shutil</code> to copy files and folders.</li> <li> <code>json</code> to edit <code>.json</code> files. </li> <li> <code>typing</code> to add type hints.   </li> </ul> <p>1. Create variables. </p> <p>add_pages_to_report.py<pre><code>project_path = Path(r\"\") # paste the path to the Power BI project folder \npages_path = project_path / \".Report\" / \"definition\" / \"pages\"\n\nnew_table_name = \"table_1\"\nnew_page_name = new_table_name\n</code></pre> 2. Create a copy of the <code>template_table</code> folder named <code>table_1</code>. </p> add_pages_to_report.py<pre><code>def copy_template_page(new_page_name: str) -&gt; None:\n    template_page_path = pages_path / \"template_table\"\n    new_page_path = pages_path / new_page_name\n    shutil.copytree(template_page_path, new_page_path)\n\n\ncopy_template_page(new_page_name)\n</code></pre> beforeafter project/.Report/definition/pages/<pre><code>\ud83d\udcc2template_table\n</code></pre> project/.Report/definition/pages/<pre><code>\ud83d\udcc2table_1\n\ud83d\udcc2template_table\n</code></pre> <p> 3. Edit <code>page.json</code> to change the name of the new report page from <code>template_table</code> to <code>table_1</code>.  </p> add_pages_to_report.py<pre><code>def edit_page_json(new_page_name: str) -&gt; None:\n    page_json = pages_path / new_page_name / \"page.json\"\n    with open(page_json, 'r') as f:\n        page_json_data = json.load(f)\n\n    page_json_data['name'] = new_page_name\n    page_json_data['displayName'] = new_page_name\n\n    with open(page_json, 'w') as f:\n        json.dump(page_json_data, f, indent=4)\n\n\nedit_page_json(new_page_name)\n</code></pre> beforeafter project/.Report/definition/pages/table_1/page.json<pre><code>\"name\": \"template_table\",\n\"displayName\": \"template_table\",\n</code></pre> project/.Report/definition/pages/table_1/page.json<pre><code>\"name\": \"table_1\",\n\"displayName\": \"table_1\",\n</code></pre> <p> 4.  Edit <code>visual.json</code> to change the semantic model table displayed in the line graph from <code>template_table</code> to <code>table_1</code>. I use a recursive function to assign <code>i.value = \"table_1\"</code> for all nested items <code>i</code> in <code>visual.json</code> such that  <code>i.key == \"Entity\"</code>.</p> add_pages_to_report.py<pre><code>def update_dict(dictionary, search_key: Hashable, new_value: Any) -&gt; None:\n    for key, value in dictionary.items():\n        if key == search_key:\n            dictionary[key] = new_value\n        elif isinstance(value, dict):\n            update_dict(value, search_key, new_value)\n        elif isinstance(value, list):\n            for element in value:\n                if isinstance(element, dict):\n                    update_dict(element, search_key, new_value)\n\n\ndef edit_visual_json(new_page_name: str, new_table_name: str) -&gt; None:\n    visual_json = pages_path / new_page_name / \"visuals\" / \"line_graph\" / \"visual.json\"\n    with open(visual_json, 'r') as f:\n        visual_json_data = json.load(f)\n\n    update_dict(visual_json_data, \"Entity\", new_table_name)\n\n    with open(visual_json, 'w') as f:\n        json.dump(visual_json_data, f, indent=4)\n\n\nedit_visual_json(\"new_page_name\", \"new_table_name\")\n</code></pre> beforeafter project/.Report/definition/pages/table_1/visuals/line_graph/visual.json<pre><code>\"Entity\": \"template_table\",\n</code></pre> project/.Report/definition/pages/table_1/visuals/line_graph/visual.json<pre><code>\"Entity\": \"table_1\",\n</code></pre>"},{"location":"power_bi_python/#new-report-pages","title":"New report pages","text":"beforeafter <p><code>project.pbip</code></p> <p></p> <p><code>project.pbip</code></p>"}]}